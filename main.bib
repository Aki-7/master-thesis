@article{Gallagher2005-gv,
  title    = {Virtual reality simulation for the operating room:
              proficiency-based training as a paradigm shift in surgical skills
              trainings},
  author   = {Gallagher, Anthony G and Ritter, E Matt and Champion, Howard and
              Higgins, Gerald and Fried, Marvin P and Moses, Gerald and Smith,
              C Daniel and Satava, Richard M},
  abstract = {SUMMARY BACKGROUND DATA: To inform surgeons about the practical
              issues to be considered for successful integration of virtual
              reality simulation into a surgical training program. The learning
              and practice of minimally invasive surgery (MIS) makes unique
              demands on surgical training programs. A decade ago Satava
              proposed virtual reality (VR) surgical simulation as a solution
              for this problem. Only recently have robust scientific studies
              supported that vision METHODS: A review of the surgical
              education, human-factor, and psychology literature to identify
              important factors which will impinge on the successful
              integration of VR training into a surgical training program.
              RESULTS: VR is more likely to be successful if it is
              systematically integrated into a well-thought-out education and
              training program which objectively assesses technical skills
              improvement proximate to the learning experience. Validated
              performance metrics should be relevant to the surgical task being
              trained but in general will require trainees to reach an
              objectively determined proficiency criterion, based on tightly
              defined metrics and perform at this level consistently. VR
              training is more likely to be successful if the training schedule
              takes place on an interval basis rather than massed into a short
              period of extensive practice. High-fidelity VR simulations will
              confer the greatest skills transfer to the in vivo surgical
              situation, but less expensive VR trainers will also lead to
              considerably improved skills generalizations. CONCLUSIONS: VR for
              improved performance of MIS is now a reality. However, VR is only
              a training tool that must be thoughtfully introduced into a
              surgical training curriculum for it to successfully improve
              surgical technical skills.},
  journal  = {Ann Surg},
  volume   = 241,
  number   = 2,
  pages    = {364--372},
  month    = feb,
  year     = 2005,
  address  = {United States},
  language = {en}
}

@article{aerospace,
  author    = {Kristoffer B. Borgen and Timothy D. Ropp and William T. Weldon},
  title     = {Assessment of Augmented Reality Technology’s Impact on Speed of Learning and Task Performance in Aeronautical Engineering Technology Education},
  journal   = {The International Journal of Aerospace Psychology},
  volume    = {31},
  number    = {3},
  pages     = {219-229},
  year      = {2021},
  publisher = {Routledge},
  doi       = {10.1080/24721840.2021.1881403},
  url       = {https://doi.org/10.1080/24721840.2021.1881403},
  eprint    = {https://doi.org/10.1080/24721840.2021.1881403},
  abstract  = {ABSTRACTObjective: This study compared learning and skill transfer among university aviation students using interactive Augmented Reality (AR) technology versus traditional paper-based instruction. While similar AR use and research in university education exists, this study piloted a comparative method assessing knowledge retention and transfer.Background: AR technology is a popular tool used in technical education. But learner behaviors observed like game play and exploration during this study could impact future learning strategy design as AR use increases.Method: 36 university undergraduate students enrolled in a university aeronautical engineering technology program were divided into AR and paper-based groups and compared on first-time task execution times for starting an aircraft auxiliary power unit (APU). A two-sample Kolmogorov-Smirnov test comparing times for task completion was used.Results: Learner task times using AR were consistently faster, replicating similar AR studies, compared to learners using paper-based. However, AR test subjects also took longer interacting with the technology, including gaming-style “play” and exploration of the digital twin AR flight deck environment. This is believed to enhance learner innovation, knowledge retention and transfer, warranting further study.Conclusion: AR users had significantly reduced task execution times. Pre-task “gamification and play” were also observed among the AR users, which could impact how educators and the industry assess and leverage learning strategies when using AR for job task training. }
}

@article{military,
  author         = {Fan, Yun-Chieh and Wen, Chih-Yu},
  title          = {A Virtual Reality Soldier Simulator with Body Area Networks for Team Training},
  journal        = {Sensors},
  volume         = {19},
  year           = {2019},
  number         = {3},
  article-number = {451},
  url            = {https://www.mdpi.com/1424-8220/19/3/451},
  issn           = {1424-8220},
  abstract       = {Soldier-based simulators have been attracting increased attention recently, with the aim of making complex military tactics more effective, such that soldiers are able to respond rapidly and logically to battlespace situations and the commander&rsquo;s decisions in the battlefield. Moreover, body area networks (BANs) can be applied to collect the training data in order to provide greater access to soldiers&rsquo; physical actions or postures as they occur in real routine training. Therefore, due to the limited physical space of training facilities, an efficient soldier-based training strategy is proposed that integrates a virtual reality (VR) simulation system with a BAN, which can capture body movements such as walking, running, shooting, and crouching in a virtual environment. The performance evaluation shows that the proposed VR simulation system is able to provide complete and substantial information throughout the training process, including detection, estimation, and monitoring capabilities.},
  doi            = {10.3390/s19030451}
}

@inproceedings{agriculture,
  author    = {Li, Hailin},
  editor    = {Li, Daoliang},
  title     = {Analysis of Virtual Reality Technology Applications in Agriculture},
  booktitle = {Computer And Computing Technologies In Agriculture, Volume I},
  year      = {2008},
  publisher = {Springer US},
  address   = {Boston, MA},
  pages     = {133--139},
  abstract  = {Agricultural information technology, especially virtual reality (VR) technology, will act the important roles in agricultural modernization and realm. Computer science and IT are both playing important roles in the development of agriculture and rural areas of the world. Combining agriculture science with IT and VR, the virtual agriculture technology explored new ways of studying and applying agriculture information technology. On the basis of concept of virtual agriculture given, the composition, application range and development direction of virtual agriculture were analyzed. On basis of above mentioned, the architecture of virtual crops which is a typical application of virtual agriculture was analyzed and studied, and the model of virtual crops was modeled using plant three-dimensional rebuild technique. It can improve the applications of VR in agriculture fields and advance the process of agricultural modernization.},
  isbn      = {978-0-387-77251-6}
}

@misc{idc-2022,
  author       = {IDC},
  title        = {AR/VR Spending in Asia/Pacific* to Reach 14.8 Billion, Driven by Remote Meetings, Training, and Collaboration, Says IDC},
  howpublished = {\url{https://www.idc.com/getdoc.jsp?containerId=prAP49932422}},
  year         = {(accessed Dec 17, 2022)}
}

@article{crystal,
  author   = {Tsao, Jeffrey and Lumsden, Charles J.},
  title    = {{CRYSTAL: Building Multicontext Virtual Environments}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  volume   = {6},
  number   = {1},
  pages    = {57-72},
  year     = {1997},
  month    = {02},
  abstract = {{Current virtual environment systems are, for the most part, dedicated to specific applications such as engineering or surgery. The CRYSTAL project applied the concept of crystals, or 3D “windows,” to segment the virtual world into independent volumes, which may interact with each other. The contents of individual crystals can be very different from crystal to crystal, so the resulting virtual environment (VE) is not restricted to any unique context, and it is suitable as a general-purpose workspace. Crystals are created and owned by independent programs called modules, which serve as functional elements of the VE. There are basic modules to provide common functions, such as navigation, wand control, and so on. Extra modules can be launched to add content and functionality to the VE, and the modules can also be terminated interactively. Unlike “pipelined” systems for VE design, CRYSTAL modules are designed to self-assemble and resolve any interface conflicts automatically. As a result, they do not place a high demand on user proficiency in customizing VEs for a variety of uses.}},
  doi      = {10.1162/pres.1997.6.1.57},
  url      = {https://doi.org/10.1162/pres.1997.6.1.57},
  eprint   = {https://direct.mit.edu/pvar/article-pdf/6/1/57/1622948/pres.1997.6.1.57.pdf}
}

@misc{openxr-overlay,
  author       = {{{The Khronos Group Inc.}}},
  title        = {The OpenXR Specification - Version 1.0.22},
  howpublished = {\url{https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html\#XR_EXTX_overlay}},
  year         = {{Accessed February 22, 2022}}
}

@masterthesis{reiling,
  doi       = {10.15368/theses.2014.73},
  url       = {https://doi.org/10.15368/theses.2014.73},
  publisher = {Robert E. Kennedy Library,  Cal Poly},
  author    = {Forrest F. Reiling.},
  title     = {Toward General Purpose 3D User Interfaces: Extending Windowing Systems to Three Dimensions},
  year      = {2014}
}

@article{studierstube,
  author   = {Schmalstieg, Dieter and Fuhrmann, Anton and Hesina, Gerd and Szalavári, Zsolt and Encarnação, L. Miguel and Gervautz, Michael and Purgathofer, Werner},
  title    = {{The Studierstube Augmented Reality Project}},
  journal  = {Presence: Teleoperators and Virtual Environments},
  volume   = {11},
  number   = {1},
  pages    = {33-54},
  year     = {2002},
  month    = {02},
  abstract = {{Our starting point for developing the Studierstube system was the belief that augmented reality, the less obtrusive cousin of virtual reality, has a better chance of becoming a viable user interface for applications requiring manipulation of complex three-dimensional information as a daily routine. In essence, we are searching for a 3-D user interface metaphor as powerful as the desktop metaphor for 2-D. At the heart of the Studierstube system, collaborative augmented reality is used to embed computer-generated images into the real work environment. In the first part of this paper, we review the user interface of the initial Studierstube system, in particular the implementation of collaborative augmented reality, and the Personal Interaction Panel, a two-handed interface for interaction with the system. In the second part, an extended Studierstube system based on a heterogeneous distributed architecture is presented. This system allows the user to combine multiple approaches— augmented reality, projection displays, and ubiquitous computing—to the interface as needed. The environment is controlled by the Personal Interaction Panel, a twohanded, pen-and-pad interface that has versatile uses for interacting with the virtual environment. Studierstube also borrows elements from the desktop, such as multitasking and multi-windowing. The resulting software architecture is a user interface management system for complex augmented reality applications. The presentation is complemented by selected application examples.}},
  doi      = {10.1162/105474602317343640},
  url      = {https://doi.org/10.1162/105474602317343640},
  eprint   = {https://direct.mit.edu/pvar/article-pdf/11/1/33/1623621/105474602317343640.pdf}
}

@article{x-window-system,
  author     = {Scheifler, Robert W. and Gettys, Jim},
  title      = {The X Window System},
  year       = {1986},
  issue_date = {April 1986},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {5},
  number     = {2},
  issn       = {0730-0301},
  url        = {https://doi.org/10.1145/22949.24053},
  doi        = {10.1145/22949.24053},
  abstract   = {An overview of the X Window System is presented, focusing on the system substrate and the low-level facilities provided to build applications and to manage the desktop. The system provides high-performance, high-level, device-independent graphics. A hierarchy of resizable, overlapping windows allows a wide variety of application and user interfaces to be built easily. Network-transparent access to the display provides an important degree of functional separation, without significantly affecting performance, which is crucial to building applications for a distributed environment. To a reasonable extent, desktop management can be custom-tailored to individual environments, without modifying the base system and typically without affecting applications.},
  journal    = {ACM Trans. Graph.},
  month      = {apr},
  pages      = {79–109},
  numpages   = {31}
}

@article{parallel-rendering,
  author  = {Molnar, S. and Cox, M. and Ellsworth, D. and Fuchs, H.},
  journal = {IEEE Computer Graphics and Applications},
  title   = {A sorting classification of parallel rendering},
  year    = {1994},
  volume  = {14},
  number  = {4},
  pages   = {23-32},
  doi     = {10.1109/38.291528}
}

@inproceedings{peuhkurinen,
  author    = {Peuhkurinen, Antti and Mikkonen, Tommi},
  title     = {Mixed Reality Application Paradigm for Multiple Simultaneous 3D Applications},
  year      = {2017},
  isbn      = {9781450353786},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3152832.3152861},
  doi       = {10.1145/3152832.3152861},
  abstract  = {Hardware that is capable of running mixed reality applications is rapidly becoming commonplace in mass markets. As this trend continues, such applications will soon be available in mobile devices, where they are naturally blended into the real world to extend the perceived reality and to improve user experience in various use cases where computing devices are already involved. With mixed reality's infinite screen, our vision is that there will be tens of applications blended into the real world, allowing users to multi task in various ways. In this paper, we study the graphics system needs for mixed reality 3D application paradigms. In particular, we compare two solutions for this problem and share our experiences from their implementations.},
  booktitle = {Proceedings of the 16th International Conference on Mobile and Ubiquitous Multimedia},
  pages     = {133–141},
  numpages  = {9},
  keywords  = {mobile devices, application paradigm, 3D applications},
  location  = {Stuttgart, Germany},
  series    = {MUM '17}
}

@article{ray-marching-math,
  author    = {Rémi Coulon and Elisabetta A. Matsumoto and Henry Segerman and Steve J. Trettel},
  title     = {Ray-Marching Thurston Geometries},
  journal   = {Experimental Mathematics},
  volume    = {31},
  number    = {4},
  pages     = {1197-1277},
  year      = {2022},
  publisher = {Taylor & Francis},
  doi       = {10.1080/10586458.2022.2030262},
  url       = {https://doi.org/10.1080/10586458.2022.2030262},
  eprint    = {https://doi.org/10.1080/10586458.2022.2030262}
}

@inproceedings{ray-marching-advanced1,
  author    = {Zhang, Bo and Oh, Kyoungsu},
  title     = {Interactive Indirect Illumination Using Mipmap-Based Ray Marching and Local Means Replaced Denoising},
  year      = {2019},
  isbn      = {9781450370011},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3359996.3364777},
  doi       = {10.1145/3359996.3364777},
  abstract  = {An interactive, one-bounce, and indirect illumination algorithm, which considers indirect visibility, is introduced. First, a ray marching algorithm (MRM), which is based on a 3D mipmap hierarchy structure generated by voxelizing the scene to accelerate the ray-voxel intersection, is used. Second, the indirect images are denoised by iterating an improved, edge-avoiding filtering with a local means replacement (LMR) method. The implementation demonstrates that our solutions can efficiently generate high-quality global illumination images even in a fully dynamic scene.},
  booktitle = {Proceedings of the 25th ACM Symposium on Virtual Reality Software and Technology},
  articleno = {74},
  numpages  = {2},
  keywords  = {Ray marching, 3D mipmap, Real-time rendering, Indirect illumination, Indirect visibility, Interactive denoising},
  location  = {Parramatta, NSW, Australia},
  series    = {VRST '19}
}

@inproceedings{ray-marching-advanced2,
  author    = {Zhou, Kun and Ren, Zhong and Lin, Stephen and Bao, Hujun and Guo, Baining and Shum, Heung-Yeung},
  title     = {Real-Time Smoke Rendering Using Compensated Ray Marching},
  year      = {2008},
  isbn      = {9781450301121},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1399504.1360635},
  doi       = {10.1145/1399504.1360635},
  abstract  = {We present a real-time algorithm called compensated ray marching for rendering of smoke under dynamic low-frequency environment lighting. Our approach is based on a decomposition of the input smoke animation, represented as a sequence of volumetric density fields, into a set of radial basis functions (RBFs) and a sequence of residual fields. To expedite rendering, the source radiance distribution within the smoke is computed from only the low-frequency RBF approximation of the density fields, since the high-frequency residuals have little impact on global illumination under low-frequency environment lighting. Furthermore, in computing source radiances the contributions from single and multiple scattering are evaluated at only the RBF centers and then approximated at other points in the volume using an RBF-based interpolation. A slice-based integration of these source radiances along each view ray is then performed to render the final image. The high-frequency residual fields, which are a critical component in the local appearance of smoke, are compensated back into the radiance integral during this ray march to generate images of high detail.The runtime algorithm, which includes both light transfer simulation and ray marching, can be easily implemented on the GPU, and thus allows for real-time manipulation of viewpoint and lighting, as well as interactive editing of smoke attributes such as extinction cross section, scattering albedo, and phase function. Only moderate preprocessing time and storage is needed. This approach provides the first method for real-time smoke rendering that includes single and multiple scattering while generating results comparable in quality to offline algorithms like ray tracing.},
  booktitle = {ACM SIGGRAPH 2008 Papers},
  articleno = {36},
  numpages  = {12},
  keywords  = {single scattering, perfect hashing, multiple scattering, participating media, environment lighting},
  location  = {Los Angeles, California},
  series    = {SIGGRAPH '08}
}

@article{meta-ball,
  author   = {Nishita, Tomoyuki and Nakamae, Eihachiro},
  title    = {A Method for Displaying Metaballs by using Bézier Clipping},
  journal  = {Computer Graphics Forum},
  volume   = {13},
  number   = {3},
  pages    = {271-280},
  keywords = {Metaballs, Blobs, Soft objects, Density function, Ray tracing, Bézier Clipping, Deformable objects, Geometric Modeling, Photo-realism},
  doi      = {https://doi.org/10.1111/1467-8659.1330271},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.1330271},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-8659.1330271},
  abstract = {Abstract For rendering curved surfaces, one of the most popular techniques is metaballs, an implicit model based on isosurfaces of potential fields. This technique is suitable for deformable objects and CSG model. For rendering metaballs, intersection tests between rays and isosurfaces are required. By defining the higher degree of functions for the field functions, richer capability can be expected, i.e., the smoother surfaces. However, one of the problems is that the intersection between the ray and isosurfaces can not be solved analytically for such a high degree function. Even though the field function is expressed by degree six polynomial in this paper (that means the degree six equation should be solved for the intersection test), in our algorithm, expressing the field function on the ray by Bézier functions and employing Bézier Clipping, the root of this function can be solved very effectively and precisely. This paper also discusses a deformed distribution function such as ellipsoids and a method displaying transparent objects such as clouds.},
  year     = {1994}
}

,
@article{sphere-tracing,
  title     = {Sphere tracing: A geometric method for the antialiased ray tracing of implicit surfaces},
  author    = {Hart, John C},
  journal   = {The Visual Computer},
  volume    = {12},
  number    = {10},
  pages     = {527--545},
  year      = {1996},
  publisher = {Springer-Verlag Berlin/Heidelberg}
}

@article{geometry-shader-research1,
  author  = {De Sorbier, Francois and Nozick, Vincent and Saito, Hideo},
  year    = {2010},
  month   = {07},
  pages   = {},
  title   = {Multi-view Rendering using GPU for 3-D Displays},
  journal = {GSTF International Journal on Computing},
  doi     = {10.5176/2010-2283_1.1.08}
}

@inproceedings{geometry-shader-research2,
  author    = {Hajagos, Bal\'{a}zs and Sz\'{e}csi, L\'{a}szl\'{o} and Cs\'{e}bfalvi, Bal\'{a}zs},
  title     = {Fast Silhouette and Crease Edge Synthesis with Geometry Shaders},
  year      = {2012},
  isbn      = {9781450319775},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2448531.2448540},
  doi       = {10.1145/2448531.2448540},
  abstract  = {We describe a technique to generate the geometry of silhouette and crease strokes in geometry shaders. This allows for single-pass, small-overhead rendering of conventional meshes. We exploit classic triangle adjacency information, but also introduce crease difference vectors associated with vertices in order to identify crease edges.},
  booktitle = {Proceedings of the 28th Spring Conference on Computer Graphics},
  pages     = {71–76},
  numpages  = {6},
  keywords  = {non-photorealistic rendering, stylistic rendering, outlines},
  location  = {Budmerice, Slovakia},
  series    = {SCCG '12}
}

@article{bump-mapping,
  author     = {Blinn, James F.},
  title      = {Simulation of Wrinkled Surfaces},
  year       = {1978},
  issue_date = {August 1978},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {12},
  number     = {3},
  issn       = {0097-8930},
  url        = {https://doi.org/10.1145/965139.507101},
  doi        = {10.1145/965139.507101},
  abstract   = {Computer generated shaded images have reached an impressive degree of realism with the current state of the art. They are not so realistic, however, that they would fool many people into believing they are real. One problem is that the surfaces tend to look artificial due to their extreme smoothness. What is needed is a means of simulating the surface irregularities that are on real surfaces. In 1973 Ed Catmull introduced the idea of using the parameter values of parametrically defined surfaces to index into a texture definition function which scales the intensity of the reflected light. By tying the texture pattern to the parameter values, the texture is guaranteed to rotate and move with the object. This is good for showing patterns painted on the surface, but attempts to simulate rough surfaces in this way are unconvincing. This paper presents a method of using a texturing function to perform a small perturbation on the direction of the surface normal before using it in the intensity calculations. This process yields images with realistic looking surface wrinkles without the need to model each wrinkle as a separate surface element. Several samples of images made with this technique are included.},
  journal    = {SIGGRAPH Comput. Graph.},
  month      = {aug},
  pages      = {286–292},
  numpages   = {7}
}

@inproceedings{normal-map,
  author    = {Cohen, Jonathan and Olano, Marc and Manocha, Dinesh},
  title     = {Appearance-Preserving Simplification},
  year      = {1998},
  isbn      = {0897919998},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/280814.280832},
  doi       = {10.1145/280814.280832},
  booktitle = {Proceedings of the 25th Annual Conference on Computer Graphics and Interactive Techniques},
  pages     = {115–122},
  numpages  = {8},
  keywords  = {texture, normal, simplification, color, attributes, maps, parameterization},
  series    = {SIGGRAPH '98}
}
